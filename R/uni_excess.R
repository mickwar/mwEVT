#' Univariate threshold excess model for climate observations and simulations
#'
#' @description
#' Fit a univariate threshold exceedance model for a processed data set. The
#' data should be in a matrix format where the first column is the time and
#' all subsequent columns contain the values of the time series.
#'
#' @param data_name         character, the name of the data, e.g. "decadal1961",
#'                          "historical", or "obs19501999", corresponding to a
#'                          processed data set.
#' @param data_dir          character, path to where the data is located
#' @param region            character, specifies the spatial region of interest
#' @param variable          character, the climate variable of interest
#' @param season            character, either "year", "summer", or "winter"
#' @param date_begin        character, in the format of "YYYY-MM-DD" marking the
#'                          beginning of the time period of interest
#' @param date_end          character, similar to date_begin, marking the end
#' @param r                 numeric, nonnegative integer, specifies the degree
#'                          of separation between clusters in a declustering
#'                          scheme. A value of r=0 means each excess is given
#'                          its own cluster. If r is not specified, it will be
#'                          selected automatically.
#' @param uq                numeric, within (0, 1), the quantile of the complete data
#'                          (includes replicates if available) that determines the
#'                          threshold
#' @param threshold         numeric, values greater than threshold are considered
#'                          excess. Defaults to the threshold given by uq, but if
#'                          specified, uq is ignored.
#' @param data_cols         numeric, intended for data sets with replicates, which
#'                          columns (i.e. replicates) should be used in the analysis?
#'                          It is assumed column 1 in the data set gives the vector
#'                          of dates, so data_cols=c(1, 4) would use the first
#'                          and fourth replicates, which are in columns two and five.
#'                          Defaults to using every column.
#' @param m.ksi,s.ksi       numeric, prior mean and sd for ksi, ksi is normal
#' @param nburn             numeric, nonnegative integer, the first nburn samples
#'                          are discared. Defaults to 80000.
#' @param nmcmc             numeric, positive integer, the number of samples that are
#'                          kept _post_ burn-in. That is, a total of nburn + nmcmc
#'                          iterations of the chain are run. Defaults to 40000.
#' @param window            numeric, during the burn-in, the covariance matrix of the
#'                          proposal distribution is changed every window iterations
#'                          to improve the acceptance rate. Also, the iteration number
#'                          is displayed every window iterations. Defaults to 500.
#' @param chain_start       numeric vector of length 2, specifying the starting
#'                          location of the Markov chain for (sigma, ksi). Defaults to
#'                          c(1, 1e-6).
#' @param months            character vector of months on which the analysis should be
#'                          performed. Expects the first three characters in lower case
#'                          of the month names, defaults to NULL.
#' @param anomaly           logical, should the analysis be performed on the
#'                          season anomalies?
#' @param return_output     logical, should the R object generated by the function
#'                          be returned by the function? The object is always saved
#'                          in a .RData file.
#'
#' @export

uni_excess = function(x, uq = 0.90, threshold, r = 0, m.ksi = 0, s.ksi = 10,
    nburn = 10000, nmcmc = 10000, window = 200, chain_init){

    require(MASS)
    require(mwbase)

    output = NULL
    output$model = data_name

    output$region = region
    output$variable = variable

    if (is.null(months)){
        output$season = season[1]
        output$months = switch(output$season,
            "winter" = c("dec", "jan", "feb"),
            "summer" = c("jun", "jul", "aug"),
            c("jan", "feb", "mar", "apr", "may", "jun",
                "jul", "aug", "sep", "oct", "nov", "dec"))
    } else {
        message(paste0("Note: `months' variable manually set, `season' variable set to `", season[1], "'.\n"))
        output$season = season[1]
        output$months = months
        }
    output$days.in.months = 0
    for (i in 1:length(output$months)){
        output$days.in.months = output$days.in.months + 
            switch(output$months[i],
                "jan"=,"mar"=,"may"=,"jul"=,"aug"=,
                "oct"=,"dec"=31,
                "apr"=,"jun"=,"sep"=,"nov"=30,
                "feb"=28)
        }
    output$anomaly = anomaly

    ### Some settings based on the data used
    output$units = switch(output$variable,
        "pr"        = "m/day",
        "tas"       = "Kelvin",
        "tasmax"    = "Kelvin",
        "tasmin"    = "Kelvin",
        NULL)
    output$units = paste0(output$units, ifelse(output$anomaly, " anomaly", ""))
    output$label = switch(output$variable,
        "pr"        = "Total Precipitation",
        "tas"       = "Average Temperature",
        "tasmax"    = "Average Maximum Temperature",
        "tasmin"    = "Average Minimum Temperature",
        NULL)
    output$main.prefix = switch(substr(output$model, 1, 7),
        "decadal" = sub("d", "D", output$model),
        "histori" = "Historical",
        "picontr" = "piControl",
        "control" = "piControl",
        "Observation")
    output$base.color = switch(substr(output$model, 1, 7),
        "decadal" = "orange",
        "histori" = "firebrick1",
        "picontr" = "dodgerblue",
        "control" = "dodgerblue",
        "gray50")

    ### Load the processed data
    file_name = paste0(data_dir, output$region, "_", output$variable,
        "_", output$model, ".txt")
    message("Reading data from ", file_name, " ...")
    dat = read.table(file_name, header = TRUE)
    if (!missing(data_cols)){
        message(paste0("Note: Using columns ", paste(unique(c(1, data_cols+1)), collapse = " "), " from data set in ", file_name, ".",
            collapse = ""))
        message("Note: It is assumed that the first column contains the dates and is always necessary.")
        dat = dat[,unique(c(1, data_cols+1))]
        }

    ### Deal with those leap years and get things all on the same time scale
    message(paste0("Indexing data within ", date_begin, " and ", date_end,
        " for months ", paste(output$months, collapse=" "), " ..."))
    if (substr(output$model, 1, 7) == "control"){
        season.ind = subset_data(dat[,1], output$months)
        dat[,1] = paste0(as.numeric(substr(dat[,1], 1, 4)) +
            as.numeric(substr(date_begin, 1, 4)) - 1, substr(dat[,1], 5, 10))
        dec.ind = c(min(grep(date_begin, dat[,1])), max(grep(date_end, dat[,1])))
        season.ind = season.ind[season.ind >= dec.ind[1] & season.ind <= dec.ind[2]]
        dat = dat[season.ind,]
    } else {
        season.ind = subset_data(dat[,1], output$months)
        ly.ind = grep("-02-29", dat[,1])
        season.ind = season.ind[!(season.ind %in% ly.ind)]
        dec.ind = c(min(grep(date_begin, dat[,1])), max(grep(date_end, dat[,1])))
        season.ind = season.ind[season.ind >= dec.ind[1] & season.ind <= dec.ind[2]]
        dat = dat[season.ind,]
        }

    output$time.dates = as.Date(dat[,1])
    output$varmat = as.matrix(dat[,2:NCOL(dat)])
    output$run.index = 1:NCOL(output$varmat)

    # Number of full years from date_begin to date_end
    nyears = length(output$time.dates) / output$days.in.months

    if (output$anomaly){
        message("Calculating seasonal anomalies ...")
        tmp = cbind(seq(1,
                by = length(season.ind) / nyears,
                length.out = nyears),
            seq(length(season.ind) / nyears,
                by = length(season.ind) / nyears,
                length.out = nyears))
        for (i in 1:NROW(tmp)){
            for (j in 1:NCOL(output$varmat)){
                output$varmat[seq(tmp[i,1], tmp[i,2]), j] = 
                    output$varmat[seq(tmp[i,1], tmp[i,2]), j] -
                    mean(output$varmat[seq(tmp[i,1], tmp[i,2]), j])
                }
            }
        rm(tmp)
        }

    if (missing(threshold)){
        output$uq = uq
        output$threshold = as.numeric(quantile(c(output$varmat), output$uq))
    } else {
        message("Note: value for `threshold' specified, overriding value for `uq'.\n")
        output$uq = NULL
        output$threshold = threshold
        }

    if (missing(r))
        output$r = r.select(output)

    ## This group runs together
    message("Retrieving excesses ...")
    output$y = NULL
    output$n_c = 0
    output$n_u = 0
    output$n = 0
    for (j in 1:length(output$run.index)){
        tmp = decluster(x = output$varmat[,output$run.index[j]],
            times = output$time.dates, u = output$threshold,
            r = output$r, doplot = FALSE)
        output$y = c(output$y, tmp$max_cluster_excess)
        output$n_c = output$n_c + tmp$n_clust
        output$n_u = output$n_u + tmp$n_u
        output$n = output$n + tmp$n
        }
    rm(tmp)
    ## End group

    ### MCMC
    nparam = 2
    params = matrix(0, nburn + nmcmc, nparam)
    accept = double(nburn + nmcmc)
    cand.sig = diag(0.1, nparam)

    params[1,] = chain_start

    lower = c(0, -Inf)
    upper = c(Inf, Inf)

    calc.post = function(x, params){
        # x is a list where x$y is the exceedances, x$n_c is the number of clusters
        sigma = params[1]
        ksi = params[2]
        # (lower) boundary check
        if (any(1 + ksi*x$y/sigma < 0))
            return (-Inf)
        # Likelihood
        if (ksi != 0){
            out = -x$n_c*log(sigma) - (1 + 1/ksi)*sum(log(1+ksi*x$y/sigma))
        } else {
            out = -x$n_c*log(sigma) - sum(x$y)/sigma
            }
        # Priors
        out = out - log(sigma)
        out = out + dnorm(ksi, m.ksi, s.ksi, log = TRUE)
        return (out)
        }

    post = calc.post(output, params[1,])

    message("Obtaining posterior samples ...")
    for (i in 2:(nburn + nmcmc)){
        if (floor(i/window) == i/window)
            cat("\r   ", i, "/", nburn+nmcmc)
        params[i,] = params[i-1,]
        cand = mvrnorm(1, params[i-1,], cand.sig)
        if (all(cand > lower) && all(cand < upper)){
            cand.post = calc.post(output, cand)
            if (log(runif(1)) <= cand.post - post){
                post = cand.post
                params[i,] = cand
                accept[i] = 1
                }
            }
        if ((floor(i/window) == i/window) && (i <= nburn))
            cand.sig = autotune(mean(accept[(i-window+1):i]), target = 0.234, k = window/50) *
                (cand.sig + window * var(params[(i-window+1):i,]) / i)
        if (i == (nburn + nmcmc))
            cat("\n")
        }

    params = tail(params, nmcmc)
    accept = tail(accept, nmcmc)

    ### Beta(1/2, 1/2) priors assumed for zeta and theta
    # output$n_u/output$n   # zeta mle
    zeta = rbeta(nmcmc, output$n_u + 1/2, output$n - output$n_u + 1/2)

    # output$n_c/output$n_u # theta mle
    theta = rbeta(nmcmc, output$n_c + 1/2, output$n_u - output$n_c + 1/2)

    params = cbind(params, zeta, theta)
    colnames(params)[1:2] = c("sigma", "ksi")

    output$params = params
    output$accept = accept
    output$cand.sig = cand.sig

    output$hpds = lapply(apply(params, 2, function(x) list(range(hpd_mult(x)))), "[[", 1)

    ### Calculations for diagnostic plots
    message("Computing return levels and other diagnostics ...")
    tmp = diag_computations(output, llu = 100, additional.return.periods = c(20, 30, 50))
    output$return.period = tmp$return.period
    output$lm1           = tmp$lm1
    output$lq1           = tmp$lq1
    output$lm2           = tmp$lm2
    output$lq2           = tmp$lq2
    output$Zm            = tmp$Zm
    output$Zq            = tmp$Zq              
    rm(tmp)

    ### Compute DIC
    d.theta = apply(output$params, 1, function(x) -2*sum(log(dgpd(output$y, 0, x[1], x[2])/length(output$y))))
    output$DIC = mean(d.theta) + 0.5*var(d.theta)

    obj.name = paste0(output$region, "_", output$variable, "_", output$model,
        "_", ifelse(output$anomaly, "anom_", ""), output$season, "_",
        gsub("-", "", date_begin), "_", gsub("-", "", date_end))
    assign(obj.name, output)

    if (!dir.exists("./RData/"))
        dir.create("./RData/")
    save(list = obj.name, file = paste0("./RData/", obj.name, ".RData"))
    message("Note: R object saved in:")
    message(paste0("    ", getwd(), "/RData/", obj.name, ".RData\n"))

    if (return_output)
        return (output)
    }
